{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nghia/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/nghia/tmp/nghia/mnist/train-images-idx3-ubyte.gz\n",
      "Numer of images:1059\n",
      "Number of rows and cols: 28, 28\n",
      "Extracting /Users/nghia/tmp/nghia/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/nghia/tmp/nghia/mnist/test-images-idx3-ubyte.gz\n",
      "Numer of images:1059\n",
      "Number of rows and cols: 28, 28\n",
      "Extracting /Users/nghia/tmp/nghia/mnist/test-labels-idx1-ubyte.gz\n",
      "Validation size=10\n",
      "len(train_images)=1059\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "len(train_images) after filter=1041\n",
      "len(train_labels) after filter=1041\n",
      "number of examples:1041\n",
      "number of examples:10\n",
      "number of examples:1051\n",
      "shape:(50, 784)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import emnist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#from IPython.display import display, Image\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "subset = [0,1,2,3,4,5,6,7,8,9]  \n",
    "mnist = emnist.read_data_sets('/Users/nghia/tmp/nghia/mnist', prefix=\"\", validation_size=10, subset = subset) \n",
    "#mnist = emnist.read_data_sets('data/emnist', subset = subset)\n",
    "\n",
    "#Debugging\n",
    "print(\"shape:\" + str(mnist.train.next_batch(50)[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.train.next_batch(50): (50, 784)\n",
      "mnist.test_images.shape (1051, 784)\n",
      "mnist.test_labels.shape (1051, 10)\n",
      "WARNING:tensorflow:From /Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, training accuracy 0\n",
      "test accuracy 0.0133206\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parent directory of /Users/nghiaround/rec_table/train/checkpoint/abc doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /Users/nghiaround/rec_table/train/checkpoint; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, W_conv1, W_conv1/Adam, W_conv1/Adam_1, W_conv2, W_conv2/Adam, W_conv2/Adam_1, W_fc1, W_fc1/Adam, W_fc1/Adam_1, W_fc2, W_fc2/Adam, W_fc2/Adam_1, b_conv1, b_conv1/Adam, b_conv1/Adam_1, b_conv2, b_conv2/Adam, b_conv2/Adam_1, b_fc1, b_fc1/Adam, b_fc1/Adam_1, b_fc2, b_fc2/Adam, b_fc2/Adam_1, beta1_power, beta2_power, global_step)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /Users/nghiaround/rec_table/train/checkpoint; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, W_conv1, W_conv1/Adam, W_conv1/Adam_1, W_conv2, W_conv2/Adam, W_conv2/Adam_1, W_fc1, W_fc1/Adam, W_fc1/Adam_1, W_fc2, W_fc2/Adam, W_fc2/Adam_1, b_conv1, b_conv1/Adam, b_conv1/Adam_1, b_conv2, b_conv2/Adam, b_conv2/Adam_1, b_fc1, b_fc1/Adam, b_fc1/Adam_1, b_fc2, b_fc2/Adam, b_fc2/Adam_1, beta1_power, beta2_power, global_step)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/Users/nghia/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/nghia/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-71d553412c10>\", line 73, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): /Users/nghiaround/rec_table/train/checkpoint; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, W_conv1, W_conv1/Adam, W_conv1/Adam_1, W_conv2, W_conv2/Adam, W_conv2/Adam_1, W_fc1, W_fc1/Adam, W_fc1/Adam_1, W_fc2, W_fc2/Adam, W_fc2/Adam_1, b_conv1, b_conv1/Adam, b_conv1/Adam_1, b_conv2, b_conv2/Adam, b_conv2/Adam_1, b_fc1, b_fc1/Adam, b_fc1/Adam_1, b_fc2, b_fc2/Adam, b_fc2/Adam_1, beta1_power, beta2_power, global_step)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-71d553412c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test accuracy %g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After save data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1592\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1593\u001b[0m                   save_path))\n\u001b[0;32m-> 1594\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of /Users/nghiaround/rec_table/train/checkpoint/abc doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "def weight_variable(shape, name):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W, name=None):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "image_size = 28\n",
    "num_label = len(subset)\n",
    "num_steps = 1\n",
    "\n",
    "graph = tf.Graph()\n",
    "print(\"mnist.train.next_batch(50):\" ,mnist.train.next_batch(50)[0].shape)\n",
    "with graph.as_default():  \n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, num_label], name='y_')\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "       \n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], 'W_conv1')\n",
    "    b_conv1 = bias_variable([32], 'b_conv1')\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1], name='x_image')\n",
    "                        \n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='h_conv1')\n",
    "    h_pool1 = max_pool_2x2(h_conv1, 'h_pool1')\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64], 'W_conv2')\n",
    "    b_conv2 = bias_variable([64], 'b_conv2')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2, 'h_pool2')\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024], 'W_fc1')\n",
    "    b_fc1 = bias_variable([1024], 'b_fc1')\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    W_fc2 = weight_variable([1024, num_label], 'W_fc2')\n",
    "    b_fc2 = bias_variable([num_label], 'b_fc2')\n",
    "\n",
    "    y_conv = tf.identity(tf.matmul(h_fc1_drop, W_fc2) + b_fc2,name='y_conv')\n",
    "    \n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv), name='cross_entropy')\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy, name='train_step')\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "    tf.add_to_collection('y_conv', y_conv)\n",
    "    tf.add_to_collection('accuracy', accuracy)\n",
    "    tf.add_to_collection('cross_entropy', cross_entropy)\n",
    "    tf.add_to_collection(\"train_step\", train_step)\n",
    "\n",
    "print('mnist.test_images.shape', mnist.test.images.shape)\n",
    "print('mnist.test_labels.shape', mnist.test.labels.shape)\n",
    "\n",
    "trained_filename = '/Users/nghia/rec_table/train/checkpoint/abc'\n",
    "#print('Label ', mnist.test.labels[0:10])\n",
    "\n",
    "image_size = 28\n",
    "one_image = mnist.train.images[20] \n",
    "show_image = one_image.reshape([image_size, image_size])\n",
    "plt.imshow(show_image, aspect=\"auto\") \n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    saver = tf.train.Saver()\n",
    "    for i in range(num_steps):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            \n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    saver.save(session, trained_filename)\n",
    "    print('After save data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
