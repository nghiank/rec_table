{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nghia/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/emnist/emnist-byclass-train-images-idx3-ubyte.gz\n",
      "Numer of images:697932\n",
      "Number of rows and cols: 28, 28\n",
      "Extracting data/emnist/emnist-byclass-train-labels-idx1-ubyte.gz\n",
      "Extracting data/emnist/emnist-byclass-test-images-idx3-ubyte.gz\n",
      "Numer of images:116323\n",
      "Number of rows and cols: 28, 28\n",
      "Extracting data/emnist/emnist-byclass-test-labels-idx1-ubyte.gz\n",
      "Validation size=5000\n",
      "len(train_images)=697932\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "len(train_images) after filter=342584\n",
      "len(train_labels) after filter=342584\n",
      "number of examples:342584\n",
      "number of examples:2451\n",
      "number of examples:57918\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import emnist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#from IPython.display import display, Image\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import numpy\n",
    "\n",
    "#subset = [18, 20, 27, 44, 46, 53]               # r,i,k,R,I,\n",
    "subset = [0,1,2,3,4,5,6,7,8,9]          # 0-9, x, X\n",
    "#subset = [2,3,6,7,9]\n",
    "\n",
    "mnist = emnist.read_data_sets('data/emnist', subset = subset)\n",
    "#print mnist.train.images.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W, name=None):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "\n",
    "image_size = 28\n",
    "num_label = len(subset)\n",
    "num_steps = 20\n",
    "\n",
    "graph = tf.Graph()\n",
    "print(\"mnist.train.next_batch(50):\" ,mnist.train.next_batch(50)[0].shape)\n",
    "with graph.as_default():  \n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, num_label], name='y_')\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "       \n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], 'W_conv1')\n",
    "    b_conv1 = bias_variable([32], 'b_conv1')\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1], name='x_image')\n",
    "                        \n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='h_conv1')\n",
    "    h_pool1 = max_pool_2x2(h_conv1, 'h_pool1')\n",
    "    \n",
    "    W_conv2 = weight_variable([5, 5, 32, 64], 'W_conv2')\n",
    "    b_conv2 = bias_variable([64], 'b_conv2')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2, 'h_pool2')\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024], 'W_fc1')\n",
    "    b_fc1 = bias_variable([1024], 'b_fc1')\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    W_fc2 = weight_variable([1024, num_label], 'W_fc2')\n",
    "    b_fc2 = bias_variable([num_label], 'b_fc2')\n",
    "\n",
    "    y_conv = tf.identity(tf.matmul(h_fc1_drop, W_fc2) + b_fc2,name='y_conv')\n",
    "    \n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv), name='cross_entropy')\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy, name='train_step')\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "    tf.add_to_collection('y_conv', y_conv)\n",
    "    tf.add_to_collection('accuracy', accuracy)\n",
    "    tf.add_to_collection('cross_entropy', cross_entropy)\n",
    "    tf.add_to_collection(\"train_step\", train_step)\n",
    "\n",
    "print('mnist.test_images.shape', mnist.test.images.shape)\n",
    "print('mnist.test_labels.shape', mnist.test.labels.shape)\n",
    "\n",
    "trained_filename = '/Users/nghia/rec_table/train/checkpoint/no'\n",
    "#print('Label ', mnist.test.labels[0:10])\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    saver = tf.train.Saver()\n",
    "    for i in range(num_steps):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    #print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    saver.save(session, trained_filename)\n",
    "    print('After save data')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/nghia/rec_table/train/checkpoint/lala\n",
      "Result: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107169e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imageprepare(filename):\n",
    "    \"\"\"\n",
    "    This function returns the pixel values.\n",
    "    The imput is a png file location.\n",
    "    \"\"\"\n",
    "    im = Image.open(filename).convert('L')\n",
    "    width = float(im.size[0])\n",
    "    height = float(im.size[1])\n",
    "    newImage = Image.new('L', (28, 28), (0)) #creates white canvas of 28x28 pixels\n",
    "    \n",
    "    if width > height: #check which dimension is bigger\n",
    "        #Width is bigger. Width becomes 20 pixels.\n",
    "        nheight = int(round((20.0/width*height),0)) #resize height according to ratio width\n",
    "        if (nheight == 0): #rare case but minimum is 1 pixel\n",
    "            nheight = 1\n",
    "        # resize and sharpen\n",
    "        img = im.resize((20,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wtop = int(round(((28 - nheight)/2),0)) #caculate horizontal pozition\n",
    "        newImage.paste(img, (4, wtop)) #paste resized image on white canvas\n",
    "    else:\n",
    "        #Height is bigger. Heigth becomes 20 pixels. \n",
    "        nwidth = int(round((20.0/height*width),0)) #resize width according to ratio height\n",
    "        if (nwidth == 0): #rare case but minimum is 1 pixel\n",
    "            nwidth = 1\n",
    "         # resize and sharpen\n",
    "        img = im.resize((nwidth,20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wleft = int(round(((28 - nwidth)/2),0)) #caculate vertical pozition\n",
    "        newImage.paste(img, (wleft, 4)) #paste resized image on white canvas\n",
    "    \n",
    "    #newImage.save(\"sample.png\")\n",
    "\n",
    "    tv = list(newImage.getdata()) #get pixel values\n",
    "    \n",
    "    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
    "    tva = [ (x)*1.0/255.0 for x in tv] \n",
    "    return tva\n",
    "    #print(tva)\n",
    "    \n",
    "%matplotlib inline \n",
    "image_size = 28 \n",
    "\n",
    "graph = tf.Graph() \n",
    "with graph.as_default():\n",
    "    filename = \"/Users/nghia/tmp/nghia/training-images/2/7_295.png\"\n",
    "    img = imageprepare(filename)\n",
    "tt = 900\n",
    "one_image = mnist.train.images[tt] \n",
    "show_image = one_image.reshape([image_size, image_size])\n",
    "\n",
    "predict_image = np.array(img)\n",
    "predict_image = predict_image.reshape([image_size, image_size])\n",
    "plt.imshow(predict_image, aspect=\"auto\") \n",
    "\n",
    "#show_image = numpy.flip(one_image.reshape([image_size, image_size]), 0)\n",
    "#show_image = numpy.rot90(show_image, 3)\n",
    "graph = tf.Graph() \n",
    "\n",
    "#img_input = img.reshape([1, image_size * image_size])\n",
    "#img_input = one_image.reshape([1, image_size * image_size]).astype(np.float32)\n",
    "#letter_map = ['I', 'K', 'R', 'i', 'k', 'r']\n",
    "letter_map = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "#print(\"Label:\", mnist.train.labels[tt])\n",
    "#print(\"Label:\", letter_map[np.argmax(mnist.train.labels[tt])])\n",
    "#plt.imshow(show_image, aspect=\"auto\") \n",
    "#print(show_image)\n",
    "\n",
    "trained_filename = '/Users/nghia/rec_table/train/checkpoint/lala'\n",
    "with graph.as_default():\n",
    "    new_saver = tf.train.import_meta_graph(trained_filename + '.meta') \n",
    "    x = graph.get_tensor_by_name(\"x:0\") \n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    y_conv = tf.get_collection('y_conv')[0]\n",
    "    predict = tf.argmax(y_conv, 1)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    new_saver.restore(session, trained_filename)\n",
    "    v_ = session.run(predict, feed_dict = {\"x:0\": [img], \"keep_prob:0\": 1.0}) \n",
    "    #print(v_)\n",
    "print(\"Result:\", letter_map[v_[0]])\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting retrain...\n",
      "INFO:tensorflow:Restoring parameters from /Users/nghia/rec_table/train/checkpoint/lala\n",
      "step 0, training accuracy 1\n",
      "step 1, training accuracy 1\n",
      "step 2, training accuracy 1\n",
      "step 3, training accuracy 1\n",
      "step 4, training accuracy 1\n",
      "step 5, training accuracy 1\n",
      "step 6, training accuracy 1\n",
      "step 7, training accuracy 1\n",
      "step 8, training accuracy 1\n",
      "step 9, training accuracy 1\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "# Retrain from last checkpoint \n",
    "\n",
    "trained_filename = '/Users/nghia/rec_table/train/checkpoint/lala'\n",
    "new_trained_filename = '/Users/nghia/rec_table/train/checkpoint/mama'\n",
    "num_steps = 10\n",
    "\n",
    "# We can now access the default graph where all our metadata has been loaded\n",
    "graph = tf.Graph()\n",
    "session = tf.Session(graph=graph)\n",
    "print(\"Starting retrain...\")\n",
    "with graph.as_default():\n",
    "    new_saver = tf.train.import_meta_graph(trained_filename + '.meta') \n",
    "    new_saver.restore(session, trained_filename)\n",
    "    x = graph.get_tensor_by_name(\"x:0\") \n",
    "    y_ = graph.get_tensor_by_name(\"y_:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    train_step = tf.get_collection(\"train_step\")[0]\n",
    "    accuracy = tf.get_collection('accuracy')[0]\n",
    "    for i in range(num_steps):\n",
    "        batch = mnist.train.next_batch(50) \n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = session.run(accuracy, feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))    \n",
    "            \n",
    "        session.run(train_step, feed_dict={'x:0': batch[0], 'y_:0': batch[1], keep_prob: 0.5})\n",
    "    #print('test accuracy %g' % session.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))    \n",
    "    new_saver.save(session, new_trained_filename)\n",
    "    print(\"Done!!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
