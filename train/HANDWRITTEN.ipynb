{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nghia/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/emnist/emnist-byclass-train-images-idx3-ubyte.gz\n",
      "Extracting data/emnist/emnist-byclass-train-labels-idx1-ubyte.gz\n",
      "Extracting data/emnist/emnist-byclass-test-images-idx3-ubyte.gz\n",
      "Extracting data/emnist/emnist-byclass-test-labels-idx1-ubyte.gz\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Only retain label: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import emnist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#from IPython.display import display, Image\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import numpy\n",
    "\n",
    "#subset = [18, 20, 27, 44, 46, 53]               # r,i,k,R,I,\n",
    "subset = [0,1,2,3,4,5,6,7,8,9]          # 0-9, x, X\n",
    "#subset = [2,3,6,7,9]\n",
    "\n",
    "mnist = emnist.read_data_sets('data/emnist', subset = subset)\n",
    "#print mnist.train.images.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.train.next_batch(50): (50, 784)\n",
      "mnist.test_images.shape (57918, 784)\n",
      "mnist.test_labels.shape (57918, 10)\n",
      "WARNING:tensorflow:From /Users/nghia/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, training accuracy 0.06\n",
      "step 10, training accuracy 0.26\n",
      "step 20, training accuracy 0.34\n",
      "step 30, training accuracy 0.66\n",
      "step 40, training accuracy 0.7\n",
      "step 50, training accuracy 0.82\n",
      "step 60, training accuracy 0.68\n",
      "step 70, training accuracy 0.84\n",
      "step 80, training accuracy 0.84\n",
      "step 90, training accuracy 0.88\n",
      "step 100, training accuracy 0.86\n",
      "step 110, training accuracy 0.88\n",
      "step 120, training accuracy 0.8\n",
      "step 130, training accuracy 0.94\n",
      "step 140, training accuracy 0.96\n",
      "step 150, training accuracy 0.86\n",
      "step 160, training accuracy 0.84\n",
      "step 170, training accuracy 0.88\n",
      "step 180, training accuracy 0.92\n",
      "step 190, training accuracy 0.92\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape, name):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W, name=None):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "image_size = 28\n",
    "num_label = len(subset)\n",
    "num_steps = 200\n",
    "\n",
    "graph = tf.Graph()\n",
    "print(\"mnist.train.next_batch(50):\" ,mnist.train.next_batch(50)[0].shape)\n",
    "with graph.as_default():  \n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, num_label], name='y_')\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "       \n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], 'W_conv1')\n",
    "    b_conv1 = bias_variable([32], 'b_conv1')\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1], name='x_image')\n",
    "                        \n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='h_conv1')\n",
    "    h_pool1 = max_pool_2x2(h_conv1, 'h_pool1')\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64], 'W_conv2')\n",
    "    b_conv2 = bias_variable([64], 'b_conv2')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2, 'h_pool2')\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024], 'W_fc1')\n",
    "    b_fc1 = bias_variable([1024], 'b_fc1')\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    W_fc2 = weight_variable([1024, num_label], 'W_fc2')\n",
    "    b_fc2 = bias_variable([num_label], 'b_fc2')\n",
    "\n",
    "    y_conv = tf.identity(tf.matmul(h_fc1_drop, W_fc2) + b_fc2,name='y_conv')\n",
    "    \n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv), name='cross_entropy')\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy, name='train_step')\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "    tf.add_to_collection('y_conv', y_conv)\n",
    "    tf.add_to_collection('accuracy', accuracy)\n",
    "    tf.add_to_collection('cross_entropy', cross_entropy)\n",
    "    tf.add_to_collection(\"train_step\", train_step)\n",
    "\n",
    "print('mnist.test_images.shape', mnist.test.images.shape)\n",
    "print('mnist.test_labels.shape', mnist.test.labels.shape)\n",
    "\n",
    "trained_filename = '/Users/nghiaround/rec_table/train/checkpoint/no'\n",
    "#print('Label ', mnist.test.labels[0:10])\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    saver = tf.train.Saver()\n",
    "    for i in range(num_steps):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            \n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    saver.save(session, trained_filename)\n",
    "    print('After save data')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrain from last checkpoint \n",
    "trained_filename = '/Users/nghiaround/rec_table/train/checkpoint/0_9'\n",
    "new_trained_filename = '/Users/nghiaround/rec_table/train/checkpoint/0_9_local'\n",
    "num_steps = 10\n",
    "\n",
    "# We can now access the default graph where all our metadata has been loaded\n",
    "graph = tf.Graph()\n",
    "session = tf.Session(graph=graph)\n",
    "print(\"Starting retrain...\")\n",
    "with graph.as_default():\n",
    "    new_saver = tf.train.import_meta_graph(trained_filename + '.meta') \n",
    "    new_saver.restore(session, trained_filename)\n",
    "    x = graph.get_tensor_by_name(\"x:0\") \n",
    "    y_ = graph.get_tensor_by_name(\"y_:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    train_step = tf.get_collection(\"train_step\")[0]\n",
    "    accuracy = tf.get_collection('accuracy')[0]\n",
    "    for i in range(num_steps):\n",
    "        batch = mnist.train.next_batch(50) \n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = session.run(accuracy, feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            \n",
    "        session.run(train_step, feed_dict={'x:0': batch[0], 'y_:0': batch[1], keep_prob: 0.5})\n",
    "    print('test accuracy %g' % session.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imageprepare(filename):\n",
    "    \"\"\"\n",
    "    This function returns the pixel values.\n",
    "    The imput is a png file location.\n",
    "    \"\"\"\n",
    "    im = Image.open(filename).convert('L')\n",
    "    width = float(im.size[0])\n",
    "    height = float(im.size[1])\n",
    "    newImage = Image.new('L', (28, 28), (0)) #creates white canvas of 28x28 pixels\n",
    "    \n",
    "    if width > height: #check which dimension is bigger\n",
    "        #Width is bigger. Width becomes 20 pixels.\n",
    "        nheight = int(round((20.0/width*height),0)) #resize height according to ratio width\n",
    "        if (nheight == 0): #rare case but minimum is 1 pixel\n",
    "            nheight = 1\n",
    "        # resize and sharpen\n",
    "        img = im.resize((20,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wtop = int(round(((28 - nheight)/2),0)) #caculate horizontal pozition\n",
    "        newImage.paste(img, (4, wtop)) #paste resized image on white canvas\n",
    "    else:\n",
    "        #Height is bigger. Heigth becomes 20 pixels. \n",
    "        nwidth = int(round((20.0/height*width),0)) #resize width according to ratio height\n",
    "        if (nwidth == 0): #rare case but minimum is 1 pixel\n",
    "            nwidth = 1\n",
    "         # resize and sharpen\n",
    "        img = im.resize((nwidth,20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
    "        wleft = int(round(((28 - nwidth)/2),0)) #caculate vertical pozition\n",
    "        newImage.paste(img, (wleft, 4)) #paste resized image on white canvas\n",
    "    \n",
    "    #newImage.save(\"sample.png\")\n",
    "\n",
    "    tv = list(newImage.getdata()) #get pixel values\n",
    "    \n",
    "    #normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
    "    tva = [ (x)*1.0/255.0 for x in tv] \n",
    "    return tva\n",
    "    #print(tva)\n",
    "    \n",
    "%matplotlib inline \n",
    "image_size = 28 \n",
    "\n",
    "graph = tf.Graph() \n",
    "with graph.as_default():\n",
    "    filename = \"/Users/nghiaround/Desktop/out/file229_sub_0.png\"\n",
    "    img = imageprepare(filename)\n",
    "tt = 900\n",
    "one_image = mnist.train.images[tt] \n",
    "show_image = one_image.reshape([image_size, image_size])\n",
    "\n",
    "predict_image = np.array(img)\n",
    "predict_image = predict_image.reshape([image_size, image_size])\n",
    "plt.imshow(predict_image, aspect=\"auto\") \n",
    "\n",
    "#show_image = numpy.flip(one_image.reshape([image_size, image_size]), 0)\n",
    "#show_image = numpy.rot90(show_image, 3)\n",
    "graph = tf.Graph() \n",
    "\n",
    "#img_input = img.reshape([1, image_size * image_size])\n",
    "#img_input = one_image.reshape([1, image_size * image_size]).astype(np.float32)\n",
    "letter_map = ['I', 'K', 'R', 'i', 'k', 'r']\n",
    "#letter_map = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "#print(\"Label:\", mnist.train.labels[tt])\n",
    "#print(\"Label:\", letter_map[np.argmax(mnist.train.labels[tt])])\n",
    "#plt.imshow(show_image, aspect=\"auto\") \n",
    "#print(show_image)\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    new_saver = tf.train.import_meta_graph(trained_filename + '.meta') \n",
    "    x = graph.get_tensor_by_name(\"x:0\") \n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    y_conv = tf.get_collection('y_conv')[0]\n",
    "    predict = tf.argmax(y_conv, 1)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    new_saver.restore(session, trained_filename)\n",
    "    v_ = session.run(predict, feed_dict = {\"x:0\": [img], \"keep_prob:0\": 1.0}) \n",
    "    #print(v_)\n",
    "print(\"Result:\", letter_map[v_[0]])\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
